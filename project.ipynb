{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREDICTING RIDERSHIP ON THE NEW YORK CITY SUBWAY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "\n",
    "#hourly ridership data\n",
    "hourly_ridership_api_endpoint = 'https://data.ny.gov/resource/wujg-7c2s.csv'\n",
    "response = requests.get(hourly_ridership_api_endpoint)\n",
    "with open('hourly_ridership_data.csv', 'wb') as file:\n",
    "    file.write(response.content)\n",
    "\n",
    "\n",
    "#customer journey focused 2015-2019\n",
    "journey_specific_api_endpoint = 'https://data.ny.gov/resource/r7qk-6tcy.csv'\n",
    "response = requests.get(journey_specific_api_endpoint)\n",
    "with open('journeyspecific_data_2015-19.csv', 'wb') as file:\n",
    "    file.write(response.content)\n",
    "\n",
    "#customer journey focused 2019-Present\n",
    "journey_specific_api_endpoint = 'https://data.ny.gov/resource/4apg-4kt9.csv'\n",
    "response = requests.get(journey_specific_api_endpoint)\n",
    "with open('journeyspecific_data_2019-Present.csv', 'wb') as file:\n",
    "    file.write(response.content)\n",
    "\n",
    "\n",
    "hourly_ridership_data = pd.read_csv('hourly_ridership_data.csv')\n",
    "journey_specific_data_2015_19 =pd.read_csv('journeyspecific_data_2015-19.csv')\n",
    "journey_specific_data_2019_Present = pd.read_csv('journeyspecific_data_2019-Present.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 12 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   transit_timestamp    1000 non-null   object \n",
      " 1   transit_mode         1000 non-null   object \n",
      " 2   station_complex_id   1000 non-null   int64  \n",
      " 3   station_complex      1000 non-null   object \n",
      " 4   borough              1000 non-null   object \n",
      " 5   payment_method       1000 non-null   object \n",
      " 6   fare_class_category  1000 non-null   object \n",
      " 7   ridership            1000 non-null   float64\n",
      " 8   transfers            1000 non-null   float64\n",
      " 9   latitude             1000 non-null   float64\n",
      " 10  longitude            1000 non-null   float64\n",
      " 11  georeference         1000 non-null   object \n",
      "dtypes: float64(4), int64(1), object(7)\n",
      "memory usage: 93.9+ KB\n",
      "None\n",
      "Checking Null Values ... \n",
      " ----- \n",
      " transit_timestamp      0\n",
      "transit_mode           0\n",
      "station_complex_id     0\n",
      "station_complex        0\n",
      "borough                0\n",
      "payment_method         0\n",
      "fare_class_category    0\n",
      "ridership              0\n",
      "transfers              0\n",
      "latitude               0\n",
      "longitude              0\n",
      "georeference           0\n",
      "dtype: int64\n",
      "Column Names :  Index(['transit_timestamp', 'transit_mode', 'station_complex_id',\n",
      "       'station_complex', 'borough', 'payment_method', 'fare_class_category',\n",
      "       'ridership', 'transfers', 'latitude', 'longitude', 'georeference'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "hourly_ridership_data.head()\n",
    "print(hourly_ridership_data.info())\n",
    "print(\"Checking Null Values ... \\n ----- \\n\", hourly_ridership_data.isnull().sum())\n",
    "print('Column Names : ', hourly_ridership_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Null Values ...\n",
      " ---- \n",
      " month                       0\n",
      "division                    0\n",
      "line                        0\n",
      "period                      0\n",
      "num_passengers              0\n",
      "additional_platform_time    0\n",
      "additional_train_time       0\n",
      "total_apt                   0\n",
      "total_att                   0\n",
      "over_five_mins              0\n",
      "over_five_mins_perc         0\n",
      "customer_journey_time       0\n",
      "dtype: int64\n",
      "Column Names :  Index(['month', 'division', 'line', 'period', 'num_passengers',\n",
      "       'additional_platform_time', 'additional_train_time', 'total_apt',\n",
      "       'total_att', 'over_five_mins', 'over_five_mins_perc',\n",
      "       'customer_journey_time'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "journey_specific_data_2015_19.head()\n",
    "print(\"Checking Null Values ...\\n ---- \\n\", journey_specific_data_2015_19.isnull().sum())\n",
    "print('Column Names : ', journey_specific_data_2015_19.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Null Values ...\n",
      " ---- \n",
      " month                       0\n",
      "division                    0\n",
      "line                        0\n",
      "period                      0\n",
      "num_passengers              0\n",
      "additional_platform_time    0\n",
      "additional_train_time       0\n",
      "total_apt                   0\n",
      "total_att                   0\n",
      "over_five_mins              0\n",
      "over_five_mins_perc         0\n",
      "customer_journey_time       0\n",
      "dtype: int64\n",
      "Column Names :  Index(['month', 'division', 'line', 'period', 'num_passengers',\n",
      "       'additional_platform_time', 'additional_train_time', 'total_apt',\n",
      "       'total_att', 'over_five_mins', 'over_five_mins_perc',\n",
      "       'customer_journey_time'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "journey_specific_data_2019_Present.head()\n",
    "print(\"Checking Null Values ...\\n ---- \\n\", journey_specific_data_2019_Present.isnull().sum())\n",
    "print('Column Names : ',journey_specific_data_2019_Present.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting transit_timestamp to datetime and extract month for alignment with journey_specific_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_ridership_data['transit_timestamp']= pd.to_datetime(hourly_ridership_data['transit_timestamp'])\n",
    "hourly_ridership_data['month']= hourly_ridership_data['transit_timestamp'].dt.to_period('M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine month and period in journey data to create a comparable temporal key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Journey data uses the period field to split the month into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def period_to_date(period):\n",
    "    if 'first' in period.lower():\n",
    "        return '01'\n",
    "    elif'second' in period.lower():\n",
    "        return '15'\n",
    "\n",
    "journey_specific_data_2019_Present['day'] = journey_specific_data_2019_Present['period'].apply(period_to_date)\n",
    "journey_specific_data_2019_Present['date'] = pd.to_datetime(journey_specific_data_2019_Present['month']+'-'+journey_specific_data_2019_Present['day'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aligning Station Complex and Line data using fuzzy matching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fuzzywuzzy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfuzzywuzzy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m process\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfuzzy_match_station_complex\u001b[39m(station, lines):\n\u001b[1;32m      4\u001b[0m     match, score\u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mextractOne(station, lines)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fuzzywuzzy'"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import process\n",
    "\n",
    "def fuzzy_match_station_complex(station, lines):\n",
    "    match, score= process.extractOne(station, lines)\n",
    "    return match if score>80 else None\n",
    "\n",
    "hourly_ridership_data['line']= hourly_ridership_data['station_complex'].apply(lambda x: fuzzy_match_station_complex(x, journey_specific_data_2019_Present['line'].unique()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minimal_ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
